# https://github.com/open-webui/helm-charts/tree/open-webui-4.0.6/charts/open-webui
extraEnvVars:
  - name: OLLAMA_DEBUG
    value: "1"
  - name: ENV
    value: "dev"
ingress:
  class: traefik
  enabled: true
  existingSecret: open-webui-tls-secret
  host: open-webui.k3s
  tls: true
livenessProbe:
  failureThreshold: 1
  httpGet:
    path: /health
    port: http
  periodSeconds: 10
nodeSelector:
  node-role.kubernetes.io/control-plane: "true"
ollama:
  ollama:
    gpu:
      enabled: true
      number: 1
      type: "nvidia"
    models:
      - llama3.2:1b
  persistentVolume:
    enabled: true
    size: 30Gi
  runtimeClassName: nvidia
persistence:
  size: 15Gi
podLabels:
  app.kubernetes.io/name: open-webui
readinessProbe:
  failureThreshold: 1
  httpGet:
    path: /health/db
    port: http
  periodSeconds: 10
service:
  type: LoadBalancer
startupProbe:
  failureThreshold: 20
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 30
  periodSeconds: 5
websocket:
  enabled: true
